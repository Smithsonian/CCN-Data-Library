---
title: "Quarterly Report 1.2.0"
author: "Coastal Carbon Network"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    theme: spacelab
    highlight: tango
---

<style>
.vscroll-plot {
    width: 900px;
    height: 800px;
    overflow-y: scroll;
    overflow-x: hidden;
}
</style>

```{r setup, include=FALSE}

# this sets the working directory to start where the R project is located
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

# no warnings or messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE)

library(tidyverse)
library(plotly)
library(DT)

guess_max <- 15000
```

## Library Growth

```{r}

# library_beginnings <- tibble(
#   date = as.Date(c("2018-06-01", "2018-07-01", "2018-08-01", "2018-09-01",
#                    "2018-10-01", "2018-11-01", "2018-12-01", "2019-01-01",
#                    "2019-02-01", "2019-03-01", "2019-04-01", "2019-05-01")),
#   total_cores = c(1535, 1535, 1535, 1535, 1546, 1546, 2555, 4025, 4263, 4276,
#                   4571, 5487),
#   study_IDs = c(32, 32, 32, 32, 33, 33, 34, 188, 190, 192, 194, 254),
#   # Dated cores are inclusive of WG repo-only datasets, which can't be tapped into
#   #   from this script
#   dated_cores = c(0, 0, 0, 0, 11, 11, 22, 22, 66, 70, 133, 150)
# )
# write_csv(library_beginnings, "data/library_metrics/growth_metrics.csv")

# read in table documenting figshare pubs with IDs
versions <- read_csv("docs/synthesis_resources/synthesis_history.csv")
core_versions <- versions %>% filter(table == "cores")

# read in current version
current_cores <- read_csv("data/CCN_synthesis/CCN_cores.csv", guess_max = guess_max) %>% 
  mutate(country = case_when(country == "Laos" ~ "Vietnam", T ~ country)) # spot fix for Bukoski et al 2017
current_version <- "1.2.0"

# loop through versions and harvest relevant information
if(file.exists("docs/synthesis_resources/core_synthesis_history.csv")){
  
  synthesis_history <- read_csv("docs/synthesis_resources/core_synthesis_history.csv")

  } else {
  
  synthesis_history <- data.frame()
  
  for(i in 1:nrow(core_versions)){
    
    if(core_versions$source[i] == "github"){
      temp_table <- read_csv(core_versions$filepath_id[i], guess_max = guess_max)
    } else {
      temp_table <- read_csv(paste0("https://ndownloader.figshare.com/files/", core_versions$filepath_id[i]), guess_max = guess_max)
    }
    
    # assign date and version
    temp_date <- as.Date(core_versions$date[i], format = "%m/%d/%y")
    temp_version <- core_versions$version[i]
    
    temp_df <- temp_table %>%  
      distinct(study_id, core_id) %>% 
      mutate(date = temp_date,
             version = temp_version)
    
    # compile history of synthesis in core IDs
    synthesis_history <- bind_rows(synthesis_history, temp_df)
  }
  write_csv(synthesis_history, "docs/synthesis_resources/core_synthesis_history.csv")
}

## summary stats from this table
synthesis_history_trim <- synthesis_history %>% 
  # drop some unneccessary versions (some where the core count reduced??)
  filter(version != "1.1.0") %>%  # this overestimated the core count (V1.1.1 corrected this)
  filter(!(lubridate::year(as.Date(date)) %in% c(2021))) %>% 
  # add current core version info
  bind_rows(current_cores %>% 
              select(study_id, core_id) %>% 
              mutate(version = current_version, date = Sys.Date()))
  
# plot library growth
growth_fig <- synthesis_history_trim %>% 
  count(date, version, name = "total_cores") %>% 
  
  # add a row to indicate the initial synthesis
  add_row(date = as.Date("2018-06-01"),
          version = "first",
          total_cores = 1535) %>%
  # add_row(date = Sys.Date(),
  #         version = current_version,
  #         total_cores = nrow(current_cores)) %>% 
  ggplot() +
  geom_line(aes(date, total_cores)) +
  geom_point(aes(date, total_cores)) +
  xlab("Date") + ylab("Sediment Sample Count") +
  theme_bw()
ggsave(growth_fig, filename = "docs/quarterly_reports/v120/library_growth.jpg")

ggplotly(growth_fig)
```

### Habitat Sampling

```{r}
# derive more insight
# this is taking the approach of subsetting the current version of the synthesis
# instead of working directly with past versions 

## Approach
# The analyses should be done on the most current version of the database because 
# we revised habitats or coordinates for existing studies, it wouldn't be reflected
# work with the documentation of what cores were included in each version

habitat_change <- data.frame()
quality_change <- data.frame()
sampling_depths <- data.frame()
  
for(v in unique(synthesis_history_trim$version)){
  
  # subset synthesis history to identify studies and cores for a particular version
  temp_version <- synthesis_history_trim %>% filter(version == v) %>% 
    # make some fixes to study IDs that should align things better
    mutate(study_id = gsub("[.]", "", study_id),
           study_id = case_when(grepl(" ", study_id) ~ gsub(" ", "_", study_id), T ~ study_id))
  
  # subset present cores table to include only the cores from this particular version iteration
  # I am sure there might be a catch here
  # subset_df <- left_join(temp_version, current_cores)
  subset_df <- current_cores %>% filter(study_id %in% unique(temp_version$study_id) | core_id %in% unique(temp_version$core_id))
  
  # extract habitat information
  habitat_change <- habitat_change %>% 
    bind_rows(
      subset_df %>% count(country, habitat) %>% 
        mutate(version = v,
               date = unique(temp_version$date))
    )
  
  # extract quality tier information 
  quality_change <- quality_change %>%
    bind_rows(data.frame(date = unique(temp_version$date),
                         version = v,
                         total_cores = nrow(subset_df),
                         stock_cores = nrow(subset_df %>% drop_na(stocks_qual_code)),
                         dated_cores = nrow(subset_df %>% drop_na(dates_qual_code)),
                         elevation_cores = nrow(subset_df %>% drop_na(elevation_qual_code))))
  
  # harvest max sampling depths
  sampling_depths <- sampling_depths %>% 
    bind_rows(
      subset_df %>% select(country, habitat, max_depth) %>% 
        mutate(date = unique(temp_version$date),
               version = v)
    )
}

```

Change in Habitat Representativeness

```{r}

# habitat change through time
hab_fig <- habitat_change %>% 
  mutate(country = case_when(is.na(country) ~ "unknown", T ~ country),
         habitat = case_when(is.na(habitat) ~ "unknown", T ~ habitat)) %>% 
  
  # filter(!(habitat %in% c("upland", "algal mat"))) %>% 
  mutate(habitat = recode(habitat, "mudflat" = "unvegetated")) %>%
  group_by(date, version, habitat) %>% 
  summarise(core_count = sum(n)) %>% 
  ungroup() %>% 
  ggplot() +
  geom_line(aes(date, core_count, col = habitat)) +
  geom_point(aes(date, core_count, col = habitat)) + 
  theme_bw() + 
  ggtitle("Data Library Growth Across Habitat Types")

ggplotly(hab_fig)

ggsave(plot = hab_plot, filename = "docs/quarterly_reports/v120/library_growth_habitat.jpg")

```


Change in Data Quality Tier

```{r}
# conver to Long format for plotting
quality_change_long <- quality_change %>% 
  pivot_longer(cols = -c("date", "version"), names_to = "group", values_to = "core_n") %>% 
  mutate(group = str_to_title(gsub("_", " ", group)),
         # specify the order
         group = factor(group, levels = c("Total Cores", "Stock Cores", "Dated Cores", "Elevation Cores")))
  
# Plot 
quality_growth_fig <- ggplot(quality_change_long, aes(x=date, y = core_n, fill = group)) + 
    geom_area() +
  xlab("Date") + ylab("Core Count") +
  theme_bw()

ggplotly(quality_growth_fig)

ggsave(quality_growth_fig, filename = "docs/quarterly_reports/v120/library_growth_tier.jpg")
```

Change in Sampling Depth across habitat

```{r}
simple_depths <- sampling_depths %>% 
  mutate(
    depth_flag = case_when(max_depth < 20  ~ "<20cm",
                           max_depth > 20 & max_depth <= 100 ~ "20-100cm",
                                max_depth > 100 ~ ">100cm",
                                T ~ "unknown"),
         # depth_flag = case_when(max_depth < 20 ~ "<20cm",
         #                        max_depth <= 100 ~ "20-100cm",
         #                        max_depth > 100 & max_depth <= 200 ~ "100-200cm",
         #                        max_depth > 200 & max_depth <= 300 ~ "200-300cm",
         #                        max_depth > 300 ~ ">300cm",
         #                         T ~ "unknown"),
         habitat = case_when(is.na(habitat) ~ "unknown", 
                             habitat == "mudflat" ~ "unvegetated",
                             T ~ habitat)) %>% 
  count(date, version, habitat, depth_flag)

depth_fig <- simple_depths %>% 
  filter(!(habitat %in% c("unknown", "upland", "algal mat"))) %>% 
  ggplot(aes(x=date, y = n, col = depth_flag)) + 
    geom_line() + geom_point() +
    facet_wrap(~habitat, scales = "free_y") +
  xlab("Date") + ylab("Core Count") +
  theme_bw()
  
ggplotly(depth_fig)

ggsave(depth_fig, filename = "docs/quarterly_reports/v120/library_growth_sampling_depth.jpg")

```


<div class="vscroll-plot">
```{r fig.height=30, fig.width=12, eval=FALSE}
# Kind of busy, lets leave out

# country change through time
habitat_smry <- habitat_change %>% 
  filter(!is.na(country)) %>% filter(!is.na(habitat)) %>% 
  # filter(habitat != "upland") %>% 
  # mutate(country = case_when(is.na(country) ~ "unknown", T ~ country),
         # habitat = case_when(is.na(habitat) ~ "unknown", T ~ habitat)) %>% 
  
  # filter(country == "United States") %>%
  
  # group and tally the unvegetated category
  mutate(habitat = recode(habitat, 
                          "mudflat" = "unvegetated",
                          "upland" = "other", 
                          "algal mat" = "other")) %>%
  group_by(date, version, country, habitat) %>%
  summarise(core_count = sum(n)) %>%
  ungroup()
  
  
ggplot(habitat_smry) +
  geom_line(aes(date, core_count, col = habitat)) +
  geom_point(aes(date, core_count, col = habitat)) + 
  facet_wrap(~country, scales = "free_y", ncol = 4) +
  scale_y_continuous(breaks = scales::pretty_breaks()) +
  theme_bw()

# ggplotly(country_plot)

```
</div>



## Current Stats (Global)

### What's New

```{r}
# isolate the most recent two versions of the synthesis
previous_version <- core_versions %>% 
  filter(version != "1.1.0") %>%  # this overestimated the core count (V1.1.1 was the correction)
  arrange(desc(version)) %>% 
  head(1) %>% pull(version)

# current <- synthesis_history_trim %>% filter(version == last_two[1]) %>% select(study_id, core_id)
previous <- synthesis_history_trim %>% filter(version == previous_version) %>% select(study_id, core_id)

new <- anti_join(current_cores, previous)

```

Stats

```{r}

length(unique(new$study_id)) # new studies
nrow(new %>% distinct(study_id, core_id)) # new cores
nrow(new %>% drop_na(dates_qual_code)) # how many are dated

new_country_hab <- new %>% count(country, habitat)

```

Contributions

```{r}
# top contributors 
new %>% count(study_id, name = "core_count") %>% arrange(desc(core_count))

```

Sediment Sampling Effort

```{r}
# Choropleth Map of Countries with New Cores
# resource: https://r-charts.com/spatial/maps-ggplot2/

library(rnaturalearth)

new_country <- new %>% drop_na(country) %>% count(country, name = "core_count") %>% 
  mutate(country = recode(country, "Russian Federation" = "Russia"))

# world with naturalearth data
world_ne <- ne_countries(returnclass = "sf",
                     # type = "countries",
                     scale = "medium") %>% 
  rename(country = sovereignt) %>% 
  mutate(country = recode(country, "United States of America" = "United States"))
names(world_ne)

world_ne_cores <- left_join(world_ne, new_country) %>% 
  arrange(desc(core_count)) %>% 
  select(country, core_count, everything())

ne_map <- ggplot(data = world_ne_cores) +
  geom_sf(color = "white", width = 0.5, aes(fill = core_count,
                                           text = paste("Country:", country, "\nNew Cores:", core_count))) +
  coord_sf(crs = "+proj=robin") +
  # coord_sf(ylim = c(-60, 80), expand = FALSE) +
  # theme_void()
  theme_bw()
  # geom_point(data = data_unique, aes(x = Longitude, y = Latitude, 
                                       # color = Source), size = 3, alpha = 0.4)+
  # scale_size(range = c(2,8))+
  # theme(legend.position = "bottom")+
  # guides(col = guide_legend(ncol = 2))+
  # guides(colour = guide_legend(override.aes = list(alpha = 1)))

# Static
print(ne_map)
ggsave(ne_map, filename = "docs/quarterly_reports/v120/new_cores_map.jpg")

```

```{r}
## Table to go with static plot
new %>% 
  drop_na(country) %>% 
  group_by(country, habitat) %>% 
  summarize(core_count = n(),
            # sources = paste(unique(study_id), collapse = ", ")
            sources = paste(unique(study_id), collapse = ", ")) %>% 
  mutate(country = recode(country, "Russian Federation" = "Russia"))
  arrange(desc(core_count)) %>% 
  
datatable(rownames = FALSE)

```

```{r}
# Make it interactive
ggplotly(ne_map + theme(legend.position = "none"), tooltip = "text")
```

### State of the Data

```{r}
# Choropleth Map of Total Cores for all Countries

country_cores <- current_cores %>% drop_na(country) %>% count(country, name = "core_count") %>% 
  mutate(country = recode(country, "Russian Federation" = "Russia")) 

# world with naturalearth data
world_ne <- ne_countries(returnclass = "sf",
                     # type = "countries",
                     scale = "medium") %>% 
  rename(country = sovereignt) %>% 
  mutate(country = recode(country, "United States of America" = "United States"))
names(world_ne)

world_country_cores <- left_join(world_ne, country_cores)

map_country_cores <- ggplot(data = world_country_cores) +
  geom_sf(color = "white", size = 0.5, aes(fill = core_count,
                                           text = paste("Country:", country, "\nTotal Cores:", core_count))) +
  coord_sf(crs = "+proj=robin") +
  theme_bw()

# print(ne_map)
ggplotly(map_country_cores + theme(legend.position = "none"), tooltip = "text")
```

```{r}
# Static Maps with maps library
# library(maps)
# 
# world <- map_data("world")
# sort(names(world))
# 
# ggplot(data = world) +
#   # geom_sf() +
#     geom_polygon(data = world, aes(x = long, y = lat, group = group), fill="white", color="grey")

```

```{r}
## Interactive Map with Leaflet
```

Habitat

```{r fig.width=12, fig.height=12}
habitat_change %>%
    filter(version == current_version) %>% 
    filter(!is.na(country)) %>% filter(!is.na(habitat)) %>% 
  # group and tally the unvegetated category
  mutate(habitat = recode(habitat, 
                          "mudflat" = "unvegetated",
                          "upland" = "other", 
                          "algal mat" = "other")) %>%
  group_by(date, version, country, habitat) %>%
  summarise(core_count = sum(n)) %>%
  ungroup() %>% 
  mutate(country = recode(country, "Democratic Republic of the Congo" = "DRC")) %>% 
  
  ggplot(aes(core_count, country, 
             size = core_count,
             color = habitat)) + 
  geom_point() +
  # ggbreak::scale_x_break(c(2000, 3500)) +
  theme_bw(base_size = 15) +
  xlab("Number of Cores") + ylab("")

# ggplotly(p)
  # print(p)
```

```{r}

```


## Current Stats (US)

### What's New

```{r}

new_us_states <- new %>% filter(country == "United States") %>% 
  group_by(admin_division, habitat) %>% 
    summarize(n = n(),
              # collapse list of unique studies for each
              studies = paste(unique(study_id), collapse = ", "))

new_dated <- new %>% filter(!is.na(dates_qual_code)) %>% group_by(country, admin_division, habitat) %>% 
  summarize(n = n(),
            studies = paste(unique(study_id), collapse = ", ")) %>% 
  arrange(admin_division)
```


Contributions

```{r}
contributors_us <- new %>% 
  filter(country == "United States") %>% 
  mutate(dated_core_flag = case_when(!is.na(dates_qual_code) ~ 1, T ~ 0)) %>% 
  group_by(study_id) %>% 
  summarize(total_core_count = n(),
            dated_core_count = sum(dated_core_flag),
            states = paste(unique(admin_division), collapse = ", "),
            habitats = paste(unique(habitat), collapse = ", ")) %>% 
  
  # count(study_id, name = "core_count") %>% 
    arrange(desc(total_core_count))

datatable(contributors_us)
```

### State of the Data

**Habitat Representation**

```{r}

current_cores %>% 
  filter(country == "United States") %>% 
  group_by(habitat) %>%
  tally() %>%
  ungroup() %>%
  mutate(percent = 100*(n/sum(n))) %>% 
  mutate(habitat = fct_reorder(habitat, percent)) %>% 
  filter(!is.na(habitat)) %>% 
  ggplot(aes(habitat, percent, fill = percent)) + 
  geom_col(fill = "darkgreen") + 
  coord_flip() + 
  # scale_color_brewer(palette = "BuGn") +
  xlab("Habitat Type") + ylab("Proportion of Cores (%)") +
  geom_text(aes(label = paste0("n=", n)), size = 3.5, hjust = -0.2) +
  # geom_text(aes(label = paste0(round(percent, 1), "%")), size = 3.5, hjust = -0.2) +
  ylim(0, 80) +
  # theme_classic() +
  theme_classic() +
  ggtitle("Habitat Sampling Proportions (US)")

ggsave("docs/quarterly_reports/v120/US_habitat_pct_barplot.jpg", width = 6, height = 6)
```

**Blue Carbon Report Card**
